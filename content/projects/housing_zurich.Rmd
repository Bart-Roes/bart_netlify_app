---
title: "Finding a place in Zurich"
author: "Bart Roes"
date: "2020-05-09"
categories:
- R
- Shiny
- Visualisation
tags:
- R Markdown
- Shiny
- R
slug: projects
---

# The Rationale

Finding an apartment in Zurich can turn out to be challenging. Not that there
are not enough houses to be found, but to find one that is both affordable as well as 
well-connected can prove to be difficult. After spending a fair amount of time searching through apartment aggregators, I decided it was time for a programme to do much of the heavy lifting for me instead.  
  
In this post I will walk through how to retrieve information from the internet
and subsequently visualise it as you please. Adding a shiny plug-in would
further allow you to play with some of the filters (in this case my monthly budget).  
  
# The Code

## Setup
  
In the code I used the `robotstxt`, `xml2` and `rvest` to retrieve
information of the internet, `magrittr` and `tidyverse` for general readability,
`glue` and `foreach` to dynamically loop through retrieved sets and finally
`leaflet` for the visualisation. `jsonlite` is used to parse the general JSON
structure to a format easily interpreted by R.  

```{r setup, error = FALSE, warning = FALSE, message = FALSE, results='hide'}
#### Loading the required libraries ####
library(robotstxt)
library(xml2)
library(rvest)
library(magrittr)
library(tidyverse)
library(glue)
library(foreach)
library(leaflet)
library(jsonlite)
```

## Robotsxt

To make sure webscraping from the selected domains is completely legal,
we can first check the respective url's with the `paths_allowed` function.  
For the purpose of this example, we will stick to using the homegate.ch website.
  

```{r robotstxt, error = FALSE, warning = FALSE, message = FALSE, results='hide'}
#### Making sure scraping is allowed ####
paths_allowed(
  path = "https://www.homegate.ch/mieten/immobilien",
  domain = "https://www.homegate.ch/"
) # if the function returns TRUE you are free to access it

# Get entire robotstxt file
# get_robotstxt(domain = "https://www.homegate.ch/")
```
  
## Variable Setup  
  
As much I would have loved to live by the lakeside, I had to put some constraints
to my housing search. As such, I decided to only look for apartments that would cost
me under 2k CHF per month. Again, the main source of my housing data was taken from homegate.  

```{r parameters, error = FALSE, warning = FALSE, message = FALSE, results='hide'}
# Set price limit
price_limit <- 3000

# Set housing site URL
url <- glue::glue("https://www.homegate.ch/mieten/immobilien/plz-8000/trefferliste?ah={price_limit}&ac=3&tab=list&tr=2&o=zip-asc&ep=1")

# Read the URL into R
real_estate <- read_html(url)
```
  
## Retrieve housing information

After we have defined the URL entailing the desired information, we can
commence retrieving the data. To do this, we first look into how many tabs
of results correspond to our search criteria. This can be done by selecting the
relevant html fields. The `html_nodes` function allows us to retrieve all elements
corresponding to a specific class from the requested page. To locate the 
name of the class of interest, the `SelectorGadget` plug-in in Chrome is used.  
  
```{r data_retrieval, error = FALSE, warning = FALSE, message = FALSE, results='hide'}
# Fetch all page numbers
page_numbers <- real_estate %>%
  html_nodes(".HgPaginationSelector_centerBox_FP80i span") %>%
  html_text() |> str_replace_all("[^0-9]", "")

# Only retrieve relevant page number
page_numbers <- as.double(page_numbers) %>% na.omit

#### Loop through the webpages ####
apartment_info <- foreach::foreach(i = min(page_numbers):max(page_numbers),
                 .combine = bind_rows,
                 .errorhandling = "remove") %do% {
  # Base URL
  url <- glue::glue("https://www.homegate.ch/mieten/immobilien/plz-8000/trefferliste?ah={price_limit}&ac=3&tab=list&tr=2&o=zip-asc&ep={i}")
  real_estate <- read_html(url)
  
  #### Fetch data from nodes per class #### 
  locations <- real_estate %>% 
    html_nodes(".HgListingCard_address_JGiFv") %>%
    html_text() 
  
  # Only keep true location records
  locations <- locations[stringr::str_detect(locations, "[0-9]{4}")]
  
  # number of rooms
  rooms <- real_estate %>%
    html_nodes(".HgListingRoomsLivingSpace_roomsLivingSpace_GyVgq span:nth-child(1)") %>%
    html_text()
  
  # price of the apartment
  price <- real_estate %>%
    html_nodes(".HgListingCard_price_JoPAs") %>%
    html_text() 
  
  price <- price %>%
    gsub(pattern = "\n", replacement = "") %>%
    gsub(pattern = "'", replacement = "") %>%
    gsub(pattern = ".-", replacement = "") 
  
  # number of available pictures
  pictures <- real_estate %>%
    html_nodes(".SlidesCounter_slidesCounter_VEGHw") %>%
    html_text() %>%
    str_replace_all(" 1 / ", "") |> 
    as.numeric()
  
  # link that is followed after clicking on site
  links <- (real_estate %>% 
              html_nodes("a") %>% html_attr("href"))[
                str_detect(real_estate %>% 
                             html_nodes("a") %>% html_attr("href"),
                           pattern = "(/mieten/)[0-9]{10}")
                ] %>% stringr::str_extract(., "[0-9]{10}")
  
  links <- tibble(links = links) %>%
    mutate(links = glue::glue("https://www.homegate.ch/mieten/{links}")) %>%
    .$links
  
  # joining all information together
  plz <- c()
  house_number <- c()

  for(i in 1:length(locations)) {
    plz[i] <- stringr::str_extract(locations[i], "[0-9]{4}") 
    
    house_number[i] <- stringr::str_extract(locations[i], "[0-9]{1,3}")
    house_number[i] <- case_when(nchar(house_number[i]) == 3 & substr(house_number[i],1,1) == 8 ~ NA_character_,
                                 nchar(house_number[i]) >= 1 ~ house_number[i],
                                 TRUE ~ NA_character_)
    
    locations[i] = gsub(locations[i], pattern = "[0-9]{4}", replacement = "")
  }  
  
  apartment_info <- tibble(location = locations,
                           rooms = rooms,
                           price = price,
                           plz = plz,
                           house_number = house_number,
                           pictures = pictures,
                           more_info = links)
  
  return(apartment_info)
}

```

## Geocoding the data

In order to construct a map of available apartments, simly retrieving the 
addresses is not enough. We need to be able to place the apartments on the 
map using their respective longitude and lattitude. A useful tool for retrieving
longitude and lattitude information is the website `nominatim.openstreetmap.org`.
We can call this website by attaching a string of the address of interest and
retrieve the result as a JSON object. This in turn can again be transformed into
an R list, which is readable into our environment.  
  
```{r geocode, error = FALSE, warning = FALSE, message = FALSE, results='hide'}
#### Geocode the addresses ####
geocode <- function(name, address){
  # NOMINATIM SEARCH API URL
  src_url <- "https://nominatim.openstreetmap.org/search?q="
  
  # CREATE A FULL ADDRESS
  addr <- address %>%
    gsub(pattern = "  ", replacement = " ") %>%
    gsub(pattern = "-", replacement =  " ") |> 
    gsub(pattern = " ", replacement =  "+") |> 
    stringi::stri_trans_general("Latin-ASCII")
    
  # CREATE A SEARCH URL BASED ON NOMINATIM API TO RETURN GEOJSON
  requests <- paste0(src_url, addr, "&format=geojson")
  
  # ITERATE OVER THE URLS AND MAKE REQUEST TO THE SEARCH API
  loc <- foreach(i = 1:length(requests),
                 .errorhandling = "remove",
                 .combine = bind_rows) %do% {
    
    # QUERY THE API TRANSFORM RESPONSE FROM JSON TO R LIST
    response <- read_html(requests[i]) %>%
      html_node("p") %>%
      html_text() %>%
      fromJSON()
    
    # FROM THE RESPONSE EXTRACT LATITUDE AND LONGITUDE COORDINATES
    coordinates <- response$features$geometry$coordinates[[1]]
    lon <- coordinates[1]
    lat <- coordinates[2]
    
    loc <- tibble(name = name[i], 
                  address = str_replace_all(addr[i], "%2C", ","),
                  latitude = lat, longitude = lon)
    
    return(loc)
  }
  
  return(loc)
}

geo_data <- geocode(name = apartment_info$location,
                    address = apartment_info$location)
```

## Generating the map

Once we have retrieved the coordinates of the apartments, we can plot the data.
To do this, we use the leaflet package, with in-build maps. For sake of illustration,
we additionally add a colour to the provided marker. Cheap apartments receive a 
green flag, whereas expensive ones receive a red flag. Apartments that don't display any
pricing information get a grey colour marker.  
  
Finally, we can adjust the information that is retrieved by clicking on the marker.
Here, we display the address, rent and number of rooms. For further information
one can click on the more info link.  
  
The link works as the whole file is rendered in HTML. This allows us to render
HTML specific keywords and commands like <br> for a newline and href for a link.  
  
```{r render_map, fig.align='center', fig.pos='h'}
# Add the coordinates to the original dataset
plot_data <- geo_data %>% unique() %>%
  left_join(apartment_info,
            by = c("name" = "location"))

plot_data$price = plot_data$price |> str_replace_all("[^0-9]", "")

# Colour-code the data based on the price of the apartment
getColor <- function(data) {
  lapply(data$price, function(x) {
    if(is.na(x) | x == "") {
      "gray"
    } else if(as.numeric(x) <= 2000) {
      "green"
    } else if(as.numeric(x) <= 2500){
      "orange"
    } else {
      "red"
    }
    })
}

# Specify the colour and the home icon with awesomeIcons
icons <- awesomeIcons(
  icon = "home", 
  library = "glyphicon",
  # iconColor = "#FFFFFF"
  markerColor = getColor(plot_data)
)

# Plot the final map using Leaflet
leaflet(plot_data) %>%
  addTiles() %>%
  setView(lat=47.39, lng=8.52, zoom = 12) %>%
  addAwesomeMarkers(lng = ~plot_data$longitude, 
                    lat = ~plot_data$latitude,
                    popup = paste(plot_data$name,"<br>", 
                                  "Price: ",plot_data$price,"<br>",
                                  "Rooms: ", plot_data$rooms,"<br>",
                                  sapply(plot_data$more_info, 
                                         function(x) {glue("<a href= {x}>More Info<a>")})),
                    icon = icons,
                    label = ~as.character(plot_data$name))
```

